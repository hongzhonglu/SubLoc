{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "chCOo9B3y7yu"
   },
   "source": [
    "# Instructions:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nRi84eDsib0e"
   },
   "source": [
    "Please follow the steps below, before running the script:\n",
    "\n",
    "\n",
    "1.  Navigate to `Runtime`>`Change runtime type` and select **GPU** as Hardware accelerator \n",
    "2.   Download this as .zip \n",
    "1.   Choose `Files` from the side menu\n",
    "2.   Upload the downloaded .zip file\n",
    "3.   Run the following cells in order\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UwFLhpor6E_R"
   },
   "outputs": [],
   "source": [
    "!unzip dataset.zip\n",
    "!pip install biopython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 67
    },
    "colab_type": "code",
    "id": "9UIQnLzF2taA",
    "outputId": "865f2919-2f3a-4694-e60e-55eb14024774"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow 1.x selected.\n",
      "1.15.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%tensorflow_version 1.x\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import evaluation as evaal\n",
    "import preprocessing as prp\n",
    "import functions as func\n",
    "from datetime import datetime\n",
    "from tensorflow import keras\n",
    "#print(keras.__version__)\n",
    "from keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "spOWBr3YAvqy"
   },
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9D2iS4QMAVx-"
   },
   "outputs": [],
   "source": [
    "#@title Please choose the algorithm that you want to use: { form-width: \"250px\", display-mode: \"both\" }\n",
    "algorithm = \"SVM\" #@param [\"SVM\", \"BiLSTM\"]\n",
    "\n",
    "\n",
    "\n",
    "# ========== Importing the data\n",
    "\n",
    "X, y = prp.import_data(algorithm)\n",
    "\n",
    "# =========================== Preprocessing ===============================\n",
    "\n",
    "# ========== Ordinal encoding\n",
    "\n",
    "amino_codes = ['0', 'A', 'C', 'E', 'D', 'G', 'F', 'I', 'H', 'K', 'M', 'L', 'N', 'Q', 'P', 'S', 'R', 'T', 'W', 'V', 'Y']\n",
    "non_amino_letters = ['B', 'J', 'O', 'U', 'X', 'Z']\n",
    "\n",
    "amino_mapping = prp.create_mapping(amino_codes)\n",
    " \n",
    "X['mapped_seq'] = prp.integer_encoding(X['seq'], amino_mapping) \n",
    "\n",
    "# ========== Sequence padding\n",
    "\n",
    "X_pad = pad_sequences(X['mapped_seq'], maxlen=3800, padding='post', truncating='post')\n",
    "\n",
    "# ===================== Dimensionality reduction\n",
    "\n",
    "# =========== RFE\n",
    "#reduced_X = prp.dim_reduction_RFE(X_pad, y, 100)\n",
    "# If you are using new dataset, run the above line and comment the lines in the below\n",
    "# Otherwise, in order to save time the optimal features have been saved in a file and will be read from the file (features_100.csv)\n",
    "\n",
    "feat_support = pd.read_csv('features_100.csv')\n",
    "\n",
    "X = pd.DataFrame(data=X_pad)\n",
    "reduced_X = pd.DataFrame()\n",
    "c = 0\n",
    "for index, r in feat_support.iterrows():\n",
    "    if(r[0] == True):\n",
    "        reduced_X.loc[:,c] = X.iloc[:, index]\n",
    "        c+=1\n",
    "\n",
    "if (algorithm == \"BiLSTM\"):\n",
    "    # Add the generated data (in the same order of their labels as they were added in preprocessing.py) at the end of X\n",
    "    reduced_X = prp.add_synthetics(\"dataset/cytoplasmiccytoplasmicmembrane_synthetic(cyt&cm).txt\", reduced_X)\n",
    "    reduced_X = prp.add_synthetics(\"dataset/periplasmiccytoplasmicmembrane_synthetic(per_cm&per).txt\", reduced_X)\n",
    "    reduced_X = prp.add_synthetics(\"dataset/outermembraneextracellular_synthetic(om_ext&ext).txt\", reduced_X)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TKeNHt0PBPN-"
   },
   "source": [
    "### Machine Learning models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "_W_iOE07BSaF",
    "outputId": "8ceae47d-d569-48bc-908f-f2f3efb10b16"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regular 10-fold cross-validation Bi-LSTM\n",
      "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/keras/initializers.py:119: calling RandomUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/init_ops.py:97: calling GlorotUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/init_ops.py:97: calling Orthogonal.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/init_ops.py:97: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "Train on 10917 samples, validate on 1213 samples\n",
      "Epoch 1/50\n",
      "10917/10917 [==============================] - 7s 642us/sample - loss: 1.7946 - precision: 0.3667 - val_loss: 1.3673 - val_precision: 0.8174\n",
      "Epoch 2/50\n",
      "10917/10917 [==============================] - 1s 69us/sample - loss: 1.0397 - precision: 0.7649 - val_loss: 0.9064 - val_precision: 0.7659\n",
      "Epoch 3/50\n",
      "10917/10917 [==============================] - 1s 69us/sample - loss: 0.7594 - precision: 0.8232 - val_loss: 0.7542 - val_precision: 0.8579\n",
      "Epoch 4/50\n",
      "10917/10917 [==============================] - 1s 69us/sample - loss: 0.6737 - precision: 0.8532 - val_loss: 0.6682 - val_precision: 0.8783\n",
      "Epoch 5/50\n",
      "10917/10917 [==============================] - 1s 68us/sample - loss: 0.6214 - precision: 0.8766 - val_loss: 0.6177 - val_precision: 0.8902\n",
      "Epoch 6/50\n",
      "10917/10917 [==============================] - 1s 69us/sample - loss: 0.5568 - precision: 0.8880 - val_loss: 0.5992 - val_precision: 0.8755\n",
      "Epoch 7/50\n",
      "10917/10917 [==============================] - 1s 68us/sample - loss: 0.5410 - precision: 0.8925 - val_loss: 0.5406 - val_precision: 0.8939\n",
      "Epoch 8/50\n",
      "10917/10917 [==============================] - 1s 67us/sample - loss: 0.5160 - precision: 0.8998 - val_loss: 0.5319 - val_precision: 0.9003\n",
      "Epoch 9/50\n",
      "10917/10917 [==============================] - 1s 69us/sample - loss: 0.4972 - precision: 0.9047 - val_loss: 0.5312 - val_precision: 0.8904\n",
      "Epoch 10/50\n",
      "10917/10917 [==============================] - 1s 68us/sample - loss: 0.4766 - precision: 0.9041 - val_loss: 0.5224 - val_precision: 0.9037\n",
      "Epoch 11/50\n",
      "10917/10917 [==============================] - 1s 69us/sample - loss: 0.4669 - precision: 0.9090 - val_loss: 0.4901 - val_precision: 0.8977\n",
      "Epoch 12/50\n",
      "10917/10917 [==============================] - 1s 68us/sample - loss: 0.4499 - precision: 0.9093 - val_loss: 0.5111 - val_precision: 0.8934\n",
      "Epoch 13/50\n",
      "10917/10917 [==============================] - 1s 69us/sample - loss: 0.4701 - precision: 0.9049 - val_loss: 0.5136 - val_precision: 0.9038\n",
      "Epoch 14/50\n",
      "10917/10917 [==============================] - 1s 67us/sample - loss: 0.4467 - precision: 0.9071 - val_loss: 0.4935 - val_precision: 0.9027\n",
      "Epoch 00014: early stopping\n",
      "10917/10917 [==============================] - 0s 28us/sample - loss: 0.4331 - precision: 0.9095\n",
      "Train loss:  0.43309027598630795\n",
      "Train accuracy:  0.9095455\n",
      "----------------------------------------------------------------------\n",
      "1213/1213 [==============================] - 0s 28us/sample - loss: 0.4935 - precision: 0.9034\n",
      "Test loss:  0.49349519079712334\n",
      "Test accuracy:  0.9033562\n",
      "Train on 10917 samples, validate on 1213 samples\n",
      "Epoch 1/50\n",
      "10917/10917 [==============================] - 1s 100us/sample - loss: 1.7948 - precision: 0.4342 - val_loss: 1.3675 - val_precision: 0.7640\n",
      "Epoch 2/50\n",
      "10917/10917 [==============================] - 1s 67us/sample - loss: 1.1147 - precision: 0.7826 - val_loss: 0.7492 - val_precision: 0.8008\n",
      "Epoch 3/50\n",
      "10917/10917 [==============================] - 1s 67us/sample - loss: 0.7587 - precision: 0.8267 - val_loss: 0.6056 - val_precision: 0.8441\n",
      "Epoch 4/50\n",
      "10917/10917 [==============================] - 1s 68us/sample - loss: 0.6809 - precision: 0.8297 - val_loss: 0.5694 - val_precision: 0.8603\n",
      "Epoch 5/50\n",
      "10917/10917 [==============================] - 1s 68us/sample - loss: 0.6089 - precision: 0.8582 - val_loss: 0.5471 - val_precision: 0.8614\n",
      "Epoch 6/50\n",
      "10917/10917 [==============================] - 1s 70us/sample - loss: 0.5725 - precision: 0.8642 - val_loss: 0.5121 - val_precision: 0.8755\n",
      "Epoch 7/50\n",
      "10917/10917 [==============================] - 1s 68us/sample - loss: 0.5512 - precision: 0.8731 - val_loss: 0.4615 - val_precision: 0.9092\n",
      "Epoch 8/50\n",
      "10917/10917 [==============================] - 1s 68us/sample - loss: 0.5055 - precision: 0.8934 - val_loss: 0.4573 - val_precision: 0.9046\n",
      "Epoch 9/50\n",
      "10917/10917 [==============================] - 1s 68us/sample - loss: 0.4839 - precision: 0.8956 - val_loss: 0.4301 - val_precision: 0.9059\n",
      "Epoch 10/50\n",
      "10917/10917 [==============================] - 1s 69us/sample - loss: 0.4736 - precision: 0.9011 - val_loss: 0.4203 - val_precision: 0.9141\n",
      "Epoch 11/50\n",
      "10917/10917 [==============================] - 1s 69us/sample - loss: 0.4543 - precision: 0.9068 - val_loss: 0.4109 - val_precision: 0.9137\n",
      "Epoch 12/50\n",
      "10917/10917 [==============================] - 1s 68us/sample - loss: 0.4403 - precision: 0.9056 - val_loss: 0.4002 - val_precision: 0.9099\n",
      "Epoch 13/50\n",
      "10917/10917 [==============================] - 1s 68us/sample - loss: 0.4279 - precision: 0.9092 - val_loss: 0.3973 - val_precision: 0.9120\n",
      "Epoch 14/50\n",
      "10917/10917 [==============================] - 1s 69us/sample - loss: 0.4229 - precision: 0.9105 - val_loss: 0.4071 - val_precision: 0.9066\n",
      "Epoch 15/50\n",
      "10917/10917 [==============================] - 1s 67us/sample - loss: 0.4256 - precision: 0.9088 - val_loss: 0.4066 - val_precision: 0.9060\n",
      "Epoch 16/50\n",
      "10917/10917 [==============================] - 1s 68us/sample - loss: 0.4331 - precision: 0.9086 - val_loss: 0.4158 - val_precision: 0.9038\n",
      "Epoch 00016: early stopping\n",
      "10917/10917 [==============================] - 0s 27us/sample - loss: 0.4148 - precision: 0.9088\n",
      "Train loss:  0.4147880480377253\n",
      "Train accuracy:  0.9087588\n",
      "----------------------------------------------------------------------\n",
      "1213/1213 [==============================] - 0s 29us/sample - loss: 0.4158 - precision: 0.9049\n",
      "Test loss:  0.41584698510681023\n",
      "Test accuracy:  0.90494126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 10917 samples, validate on 1213 samples\n",
      "Epoch 1/50\n",
      "10917/10917 [==============================] - 1s 105us/sample - loss: 1.7173 - precision: 0.4609 - val_loss: 1.3588 - val_precision: 0.5895\n",
      "Epoch 2/50\n",
      "10917/10917 [==============================] - 1s 68us/sample - loss: 1.1368 - precision: 0.7716 - val_loss: 0.9062 - val_precision: 0.8355\n",
      "Epoch 3/50\n",
      "10917/10917 [==============================] - 1s 68us/sample - loss: 0.8071 - precision: 0.8214 - val_loss: 0.7080 - val_precision: 0.8172\n",
      "Epoch 4/50\n",
      "10917/10917 [==============================] - 1s 67us/sample - loss: 0.6803 - precision: 0.8318 - val_loss: 0.6466 - val_precision: 0.8421\n",
      "Epoch 5/50\n",
      "10917/10917 [==============================] - 1s 68us/sample - loss: 0.6160 - precision: 0.8449 - val_loss: 0.5870 - val_precision: 0.8688\n",
      "Epoch 6/50\n",
      "10917/10917 [==============================] - 1s 67us/sample - loss: 0.5638 - precision: 0.8728 - val_loss: 0.5469 - val_precision: 0.8849\n",
      "Epoch 7/50\n",
      "10917/10917 [==============================] - 1s 68us/sample - loss: 0.5512 - precision: 0.8741 - val_loss: 0.5452 - val_precision: 0.8941\n",
      "Epoch 8/50\n",
      "10917/10917 [==============================] - 1s 68us/sample - loss: 0.5134 - precision: 0.8911 - val_loss: 0.5006 - val_precision: 0.9022\n",
      "Epoch 9/50\n",
      "10917/10917 [==============================] - 1s 68us/sample - loss: 0.4887 - precision: 0.8945 - val_loss: 0.4841 - val_precision: 0.9130\n",
      "Epoch 10/50\n",
      "10917/10917 [==============================] - 1s 67us/sample - loss: 0.4654 - precision: 0.9033 - val_loss: 0.4731 - val_precision: 0.9093\n",
      "Epoch 11/50\n",
      "10917/10917 [==============================] - 1s 69us/sample - loss: 0.4565 - precision: 0.9066 - val_loss: 0.4744 - val_precision: 0.9179\n",
      "Epoch 12/50\n",
      "10917/10917 [==============================] - 1s 68us/sample - loss: 0.4552 - precision: 0.9081 - val_loss: 0.4612 - val_precision: 0.9159\n",
      "Epoch 13/50\n",
      "10917/10917 [==============================] - 1s 68us/sample - loss: 0.4466 - precision: 0.9122 - val_loss: 0.4599 - val_precision: 0.9249\n",
      "Epoch 14/50\n",
      "10917/10917 [==============================] - 1s 67us/sample - loss: 0.4297 - precision: 0.9129 - val_loss: 0.4483 - val_precision: 0.9131\n",
      "Epoch 15/50\n",
      "10917/10917 [==============================] - 1s 67us/sample - loss: 0.4320 - precision: 0.9135 - val_loss: 0.4458 - val_precision: 0.9103\n",
      "Epoch 16/50\n",
      "10917/10917 [==============================] - 1s 69us/sample - loss: 0.4269 - precision: 0.9115 - val_loss: 0.4389 - val_precision: 0.9172\n",
      "Epoch 17/50\n",
      "10917/10917 [==============================] - 1s 68us/sample - loss: 0.4186 - precision: 0.9133 - val_loss: 0.4330 - val_precision: 0.9108\n",
      "Epoch 18/50\n",
      "10917/10917 [==============================] - 1s 69us/sample - loss: 0.4178 - precision: 0.9115 - val_loss: 0.4200 - val_precision: 0.9130\n",
      "Epoch 19/50\n",
      "10917/10917 [==============================] - 1s 68us/sample - loss: 0.4147 - precision: 0.9160 - val_loss: 0.4222 - val_precision: 0.9106\n",
      "Epoch 20/50\n",
      "10917/10917 [==============================] - 1s 69us/sample - loss: 0.3975 - precision: 0.9151 - val_loss: 0.4327 - val_precision: 0.9083\n",
      "Epoch 21/50\n",
      "10917/10917 [==============================] - 1s 68us/sample - loss: 0.4034 - precision: 0.9156 - val_loss: 0.4235 - val_precision: 0.9139\n",
      "Epoch 00021: early stopping\n",
      "10917/10917 [==============================] - 0s 28us/sample - loss: 0.3892 - precision: 0.9175\n",
      "Train loss:  0.38920731037060746\n",
      "Train accuracy:  0.9175117\n",
      "----------------------------------------------------------------------\n",
      "1213/1213 [==============================] - 0s 28us/sample - loss: 0.4235 - precision: 0.9143\n",
      "Test loss:  0.4234881439389813\n",
      "Test accuracy:  0.914324\n",
      "Train on 10917 samples, validate on 1213 samples\n",
      "Epoch 1/50\n",
      "10917/10917 [==============================] - 1s 108us/sample - loss: 1.7958 - precision: 0.4602 - val_loss: 1.3791 - val_precision: 0.6501\n",
      "Epoch 2/50\n",
      "10917/10917 [==============================] - 1s 68us/sample - loss: 1.0301 - precision: 0.7545 - val_loss: 0.8085 - val_precision: 0.8253\n",
      "Epoch 3/50\n",
      "10917/10917 [==============================] - 1s 69us/sample - loss: 0.7264 - precision: 0.8308 - val_loss: 0.6280 - val_precision: 0.8715\n",
      "Epoch 4/50\n",
      "10917/10917 [==============================] - 1s 69us/sample - loss: 0.6241 - precision: 0.8538 - val_loss: 0.5822 - val_precision: 0.8955\n",
      "Epoch 5/50\n",
      "10917/10917 [==============================] - 1s 68us/sample - loss: 0.5717 - precision: 0.8823 - val_loss: 0.5142 - val_precision: 0.8955\n",
      "Epoch 6/50\n",
      "10917/10917 [==============================] - 1s 69us/sample - loss: 0.5240 - precision: 0.8935 - val_loss: 0.4995 - val_precision: 0.8924\n",
      "Epoch 7/50\n",
      "10917/10917 [==============================] - 1s 69us/sample - loss: 0.4892 - precision: 0.9008 - val_loss: 0.4781 - val_precision: 0.8953\n",
      "Epoch 8/50\n",
      "10917/10917 [==============================] - 1s 68us/sample - loss: 0.4713 - precision: 0.8979 - val_loss: 0.4608 - val_precision: 0.8962\n",
      "Epoch 9/50\n",
      "10917/10917 [==============================] - 1s 68us/sample - loss: 0.4660 - precision: 0.9003 - val_loss: 0.4680 - val_precision: 0.9140\n",
      "Epoch 10/50\n",
      "10917/10917 [==============================] - 1s 69us/sample - loss: 0.4544 - precision: 0.9039 - val_loss: 0.4478 - val_precision: 0.9126\n",
      "Epoch 11/50\n",
      "10917/10917 [==============================] - 1s 69us/sample - loss: 0.4299 - precision: 0.9062 - val_loss: 0.4527 - val_precision: 0.9008\n",
      "Epoch 12/50\n",
      "10917/10917 [==============================] - 1s 70us/sample - loss: 0.4466 - precision: 0.9045 - val_loss: 0.4465 - val_precision: 0.9013\n",
      "Epoch 13/50\n",
      "10917/10917 [==============================] - 1s 68us/sample - loss: 0.4306 - precision: 0.9070 - val_loss: 0.4455 - val_precision: 0.9002\n",
      "Epoch 14/50\n",
      "10917/10917 [==============================] - 1s 70us/sample - loss: 0.4232 - precision: 0.9097 - val_loss: 0.4326 - val_precision: 0.9079\n",
      "Epoch 15/50\n",
      "10917/10917 [==============================] - 1s 69us/sample - loss: 0.4191 - precision: 0.9103 - val_loss: 0.4302 - val_precision: 0.9066\n",
      "Epoch 16/50\n",
      "10917/10917 [==============================] - 1s 68us/sample - loss: 0.4080 - precision: 0.9106 - val_loss: 0.4226 - val_precision: 0.9036\n",
      "Epoch 17/50\n",
      "10917/10917 [==============================] - 1s 70us/sample - loss: 0.4081 - precision: 0.9090 - val_loss: 0.4196 - val_precision: 0.9098\n",
      "Epoch 18/50\n",
      "10917/10917 [==============================] - 1s 68us/sample - loss: 0.3934 - precision: 0.9134 - val_loss: 0.4201 - val_precision: 0.9106\n",
      "Epoch 19/50\n",
      "10917/10917 [==============================] - 1s 68us/sample - loss: 0.3971 - precision: 0.9126 - val_loss: 0.4149 - val_precision: 0.9105\n",
      "Epoch 20/50\n",
      "10917/10917 [==============================] - 1s 68us/sample - loss: 0.3926 - precision: 0.9135 - val_loss: 0.4219 - val_precision: 0.9047\n",
      "Epoch 21/50\n",
      "10917/10917 [==============================] - 1s 68us/sample - loss: 0.3932 - precision: 0.9144 - val_loss: 0.4188 - val_precision: 0.9121\n",
      "Epoch 22/50\n",
      "10917/10917 [==============================] - 1s 70us/sample - loss: 0.3872 - precision: 0.9119 - val_loss: 0.4088 - val_precision: 0.9122\n",
      "Epoch 23/50\n",
      "10917/10917 [==============================] - 1s 68us/sample - loss: 0.3852 - precision: 0.9153 - val_loss: 0.4174 - val_precision: 0.9191\n",
      "Epoch 24/50\n",
      "10917/10917 [==============================] - 1s 69us/sample - loss: 0.3799 - precision: 0.9176 - val_loss: 0.4103 - val_precision: 0.9133\n",
      "Epoch 25/50\n",
      "10917/10917 [==============================] - 1s 68us/sample - loss: 0.3736 - precision: 0.9161 - val_loss: 0.4461 - val_precision: 0.8969\n",
      "Epoch 00025: early stopping\n",
      "10917/10917 [==============================] - 0s 28us/sample - loss: 0.3912 - precision: 0.9011\n",
      "Train loss:  0.3911790941168212\n",
      "Train accuracy:  0.90112543\n",
      "----------------------------------------------------------------------\n",
      "1213/1213 [==============================] - 0s 29us/sample - loss: 0.4461 - precision: 0.8955\n",
      "Test loss:  0.4460983040749486\n",
      "Test accuracy:  0.8954935\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 10917 samples, validate on 1213 samples\n",
      "Epoch 1/50\n",
      "10917/10917 [==============================] - 1s 114us/sample - loss: 1.8039 - precision: 0.3502 - val_loss: 1.5839 - val_precision: 0.8402\n",
      "Epoch 2/50\n",
      "10917/10917 [==============================] - 1s 69us/sample - loss: 1.1013 - precision: 0.7778 - val_loss: 0.8381 - val_precision: 0.8004\n",
      "Epoch 3/50\n",
      "10917/10917 [==============================] - 1s 69us/sample - loss: 0.7678 - precision: 0.8205 - val_loss: 0.7271 - val_precision: 0.8528\n",
      "Epoch 4/50\n",
      "10917/10917 [==============================] - 1s 68us/sample - loss: 0.6718 - precision: 0.8416 - val_loss: 0.6237 - val_precision: 0.8651\n",
      "Epoch 5/50\n",
      "10917/10917 [==============================] - 1s 68us/sample - loss: 0.6160 - precision: 0.8597 - val_loss: 0.6280 - val_precision: 0.8622\n",
      "Epoch 6/50\n",
      "10917/10917 [==============================] - 1s 69us/sample - loss: 0.5834 - precision: 0.8691 - val_loss: 0.6026 - val_precision: 0.8579\n",
      "Epoch 7/50\n",
      "10917/10917 [==============================] - 1s 70us/sample - loss: 0.5555 - precision: 0.8785 - val_loss: 0.5731 - val_precision: 0.8830\n",
      "Epoch 8/50\n",
      "10917/10917 [==============================] - 1s 68us/sample - loss: 0.5151 - precision: 0.8956 - val_loss: 0.5152 - val_precision: 0.8891\n",
      "Epoch 9/50\n",
      "10917/10917 [==============================] - 1s 70us/sample - loss: 0.4930 - precision: 0.8995 - val_loss: 0.5300 - val_precision: 0.8769\n",
      "Epoch 10/50\n",
      "10917/10917 [==============================] - 1s 68us/sample - loss: 0.4833 - precision: 0.9000 - val_loss: 0.4825 - val_precision: 0.9001\n",
      "Epoch 11/50\n",
      "10917/10917 [==============================] - 1s 69us/sample - loss: 0.4588 - precision: 0.9058 - val_loss: 0.4695 - val_precision: 0.9096\n",
      "Epoch 12/50\n",
      "10917/10917 [==============================] - 1s 70us/sample - loss: 0.4462 - precision: 0.9085 - val_loss: 0.4828 - val_precision: 0.8962\n",
      "Epoch 13/50\n",
      "10917/10917 [==============================] - 1s 67us/sample - loss: 0.4323 - precision: 0.9143 - val_loss: 0.4562 - val_precision: 0.9075\n",
      "Epoch 14/50\n",
      "10917/10917 [==============================] - 1s 69us/sample - loss: 0.4274 - precision: 0.9118 - val_loss: 0.4502 - val_precision: 0.9094\n",
      "Epoch 15/50\n",
      "10917/10917 [==============================] - 1s 69us/sample - loss: 0.4168 - precision: 0.9130 - val_loss: 0.4483 - val_precision: 0.9054\n",
      "Epoch 16/50\n",
      "10917/10917 [==============================] - 1s 68us/sample - loss: 0.4152 - precision: 0.9146 - val_loss: 0.4468 - val_precision: 0.9060\n",
      "Epoch 17/50\n",
      "10917/10917 [==============================] - 1s 69us/sample - loss: 0.4061 - precision: 0.9169 - val_loss: 0.4518 - val_precision: 0.9033\n",
      "Epoch 18/50\n",
      "10917/10917 [==============================] - 1s 68us/sample - loss: 0.4048 - precision: 0.9139 - val_loss: 0.4461 - val_precision: 0.9025\n",
      "Epoch 19/50\n",
      "10917/10917 [==============================] - 1s 68us/sample - loss: 0.3934 - precision: 0.9160 - val_loss: 0.4309 - val_precision: 0.9100\n",
      "Epoch 20/50\n",
      "10917/10917 [==============================] - 1s 67us/sample - loss: 0.3968 - precision: 0.9164 - val_loss: 0.4319 - val_precision: 0.9092\n",
      "Epoch 21/50\n",
      "10917/10917 [==============================] - 1s 68us/sample - loss: 0.3926 - precision: 0.9145 - val_loss: 0.4386 - val_precision: 0.9035\n",
      "Epoch 22/50\n",
      "10917/10917 [==============================] - 1s 69us/sample - loss: 0.3899 - precision: 0.9176 - val_loss: 0.4369 - val_precision: 0.8970\n",
      "Epoch 00022: early stopping\n",
      "10917/10917 [==============================] - 0s 27us/sample - loss: 0.3664 - precision: 0.9182\n",
      "Train loss:  0.3664316025733118\n",
      "Train accuracy:  0.91816634\n",
      "----------------------------------------------------------------------\n",
      "1213/1213 [==============================] - 0s 29us/sample - loss: 0.4369 - precision: 0.9001\n",
      "Test loss:  0.4369352803874979\n",
      "Test accuracy:  0.90009195\n",
      "Train on 10917 samples, validate on 1213 samples\n",
      "Epoch 1/50\n",
      "10917/10917 [==============================] - 1s 119us/sample - loss: 1.7783 - precision: 0.3190 - val_loss: 1.4657 - val_precision: 0.6889\n",
      "Epoch 2/50\n",
      "10917/10917 [==============================] - 1s 69us/sample - loss: 1.1386 - precision: 0.7269 - val_loss: 0.9519 - val_precision: 0.8792\n",
      "Epoch 3/50\n",
      "10917/10917 [==============================] - 1s 68us/sample - loss: 0.8145 - precision: 0.8118 - val_loss: 0.7178 - val_precision: 0.8268\n",
      "Epoch 4/50\n",
      "10917/10917 [==============================] - 1s 67us/sample - loss: 0.6980 - precision: 0.8276 - val_loss: 0.6587 - val_precision: 0.8685\n",
      "Epoch 5/50\n",
      "10917/10917 [==============================] - 1s 68us/sample - loss: 0.6480 - precision: 0.8478 - val_loss: 0.5897 - val_precision: 0.8699\n",
      "Epoch 6/50\n",
      "10917/10917 [==============================] - 1s 69us/sample - loss: 0.5840 - precision: 0.8754 - val_loss: 0.5661 - val_precision: 0.8791\n",
      "Epoch 7/50\n",
      "10917/10917 [==============================] - 1s 69us/sample - loss: 0.5557 - precision: 0.8793 - val_loss: 0.5239 - val_precision: 0.8939\n",
      "Epoch 8/50\n",
      "10917/10917 [==============================] - 1s 69us/sample - loss: 0.5273 - precision: 0.8847 - val_loss: 0.5169 - val_precision: 0.8807\n",
      "Epoch 9/50\n",
      "10917/10917 [==============================] - 1s 69us/sample - loss: 0.5093 - precision: 0.8862 - val_loss: 0.4852 - val_precision: 0.8855\n",
      "Epoch 10/50\n",
      "10917/10917 [==============================] - 1s 69us/sample - loss: 0.4769 - precision: 0.8974 - val_loss: 0.4654 - val_precision: 0.8893\n",
      "Epoch 11/50\n",
      "10917/10917 [==============================] - 1s 69us/sample - loss: 0.4780 - precision: 0.8919 - val_loss: 0.4575 - val_precision: 0.8884\n",
      "Epoch 12/50\n",
      "10917/10917 [==============================] - 1s 68us/sample - loss: 0.4708 - precision: 0.8985 - val_loss: 0.4591 - val_precision: 0.8914\n",
      "Epoch 13/50\n",
      "10917/10917 [==============================] - 1s 69us/sample - loss: 0.4656 - precision: 0.8957 - val_loss: 0.4456 - val_precision: 0.8871\n",
      "Epoch 14/50\n",
      "10917/10917 [==============================] - 1s 69us/sample - loss: 0.4531 - precision: 0.9033 - val_loss: 0.4718 - val_precision: 0.8917\n",
      "Epoch 15/50\n",
      "10917/10917 [==============================] - 1s 69us/sample - loss: 0.4508 - precision: 0.9018 - val_loss: 0.4590 - val_precision: 0.8873\n",
      "Epoch 16/50\n",
      "10917/10917 [==============================] - 1s 68us/sample - loss: 0.4365 - precision: 0.9033 - val_loss: 0.4409 - val_precision: 0.8956\n",
      "Epoch 17/50\n",
      "10917/10917 [==============================] - 1s 68us/sample - loss: 0.4381 - precision: 0.9031 - val_loss: 0.4374 - val_precision: 0.8929\n",
      "Epoch 18/50\n",
      "10917/10917 [==============================] - 1s 69us/sample - loss: 0.4194 - precision: 0.9085 - val_loss: 0.4196 - val_precision: 0.9023\n",
      "Epoch 19/50\n",
      "10917/10917 [==============================] - 1s 69us/sample - loss: 0.4242 - precision: 0.9117 - val_loss: 0.4246 - val_precision: 0.8982\n",
      "Epoch 20/50\n",
      "10917/10917 [==============================] - 1s 68us/sample - loss: 0.4098 - precision: 0.9090 - val_loss: 0.4163 - val_precision: 0.8988\n",
      "Epoch 21/50\n",
      "10917/10917 [==============================] - 1s 68us/sample - loss: 0.4049 - precision: 0.9124 - val_loss: 0.4147 - val_precision: 0.9052\n",
      "Epoch 22/50\n",
      "10917/10917 [==============================] - 1s 69us/sample - loss: 0.3970 - precision: 0.9136 - val_loss: 0.4258 - val_precision: 0.8960\n",
      "Epoch 23/50\n",
      "10917/10917 [==============================] - 1s 69us/sample - loss: 0.3949 - precision: 0.9155 - val_loss: 0.4108 - val_precision: 0.9079\n",
      "Epoch 24/50\n",
      "10917/10917 [==============================] - 1s 68us/sample - loss: 0.3913 - precision: 0.9140 - val_loss: 0.4131 - val_precision: 0.9048\n",
      "Epoch 25/50\n",
      "10917/10917 [==============================] - 1s 71us/sample - loss: 0.3963 - precision: 0.9155 - val_loss: 0.4042 - val_precision: 0.9161\n",
      "Epoch 26/50\n",
      "10917/10917 [==============================] - 1s 69us/sample - loss: 0.3918 - precision: 0.9121 - val_loss: 0.4179 - val_precision: 0.8996\n",
      "Epoch 27/50\n",
      "10917/10917 [==============================] - 1s 69us/sample - loss: 0.3888 - precision: 0.9128 - val_loss: 0.4061 - val_precision: 0.9035\n",
      "Epoch 28/50\n",
      "10917/10917 [==============================] - 1s 69us/sample - loss: 0.3797 - precision: 0.9189 - val_loss: 0.4033 - val_precision: 0.9140\n",
      "Epoch 29/50\n",
      "10917/10917 [==============================] - 1s 69us/sample - loss: 0.3732 - precision: 0.9163 - val_loss: 0.4123 - val_precision: 0.9071\n",
      "Epoch 30/50\n",
      "10917/10917 [==============================] - 1s 70us/sample - loss: 0.3674 - precision: 0.9182 - val_loss: 0.4015 - val_precision: 0.9082\n",
      "Epoch 31/50\n",
      "10917/10917 [==============================] - 1s 69us/sample - loss: 0.3672 - precision: 0.9200 - val_loss: 0.4084 - val_precision: 0.9050\n",
      "Epoch 32/50\n",
      "10917/10917 [==============================] - 1s 69us/sample - loss: 0.3630 - precision: 0.9204 - val_loss: 0.3949 - val_precision: 0.9081\n",
      "Epoch 33/50\n",
      "10917/10917 [==============================] - 1s 69us/sample - loss: 0.3639 - precision: 0.9171 - val_loss: 0.4184 - val_precision: 0.8971\n",
      "Epoch 34/50\n",
      "10917/10917 [==============================] - 1s 70us/sample - loss: 0.3739 - precision: 0.9146 - val_loss: 0.4105 - val_precision: 0.9035\n",
      "Epoch 35/50\n",
      "10917/10917 [==============================] - 1s 68us/sample - loss: 0.3620 - precision: 0.9224 - val_loss: 0.3865 - val_precision: 0.9061\n",
      "Epoch 36/50\n",
      "10917/10917 [==============================] - 1s 68us/sample - loss: 0.3473 - precision: 0.9218 - val_loss: 0.3955 - val_precision: 0.9125\n",
      "Epoch 37/50\n",
      "10917/10917 [==============================] - 1s 68us/sample - loss: 0.3433 - precision: 0.9235 - val_loss: 0.3995 - val_precision: 0.9010\n",
      "Epoch 38/50\n",
      "10917/10917 [==============================] - 1s 70us/sample - loss: 0.3412 - precision: 0.9222 - val_loss: 0.4113 - val_precision: 0.9062\n",
      "Epoch 00038: early stopping\n",
      "10917/10917 [==============================] - 0s 28us/sample - loss: 0.3400 - precision: 0.9236\n",
      "Train loss:  0.34001469710670984\n",
      "Train accuracy:  0.92360175\n",
      "----------------------------------------------------------------------\n",
      "1213/1213 [==============================] - 0s 29us/sample - loss: 0.4113 - precision: 0.9064\n",
      "Test loss:  0.41126664922636397\n",
      "Test accuracy:  0.9063958\n",
      "Train on 10917 samples, validate on 1213 samples\n",
      "Epoch 1/50\n",
      "10917/10917 [==============================] - 1s 125us/sample - loss: 1.8184 - precision: 0.3712 - val_loss: 1.4620 - val_precision: 0.7840\n",
      "Epoch 2/50\n",
      "10917/10917 [==============================] - 1s 70us/sample - loss: 1.1207 - precision: 0.7912 - val_loss: 0.8871 - val_precision: 0.8072\n",
      "Epoch 3/50\n",
      "10917/10917 [==============================] - 1s 69us/sample - loss: 0.8632 - precision: 0.8044 - val_loss: 0.7842 - val_precision: 0.8389\n",
      "Epoch 4/50\n",
      "10917/10917 [==============================] - 1s 70us/sample - loss: 0.7434 - precision: 0.8180 - val_loss: 0.6862 - val_precision: 0.8331\n",
      "Epoch 5/50\n",
      "10917/10917 [==============================] - 1s 70us/sample - loss: 0.6564 - precision: 0.8489 - val_loss: 0.6496 - val_precision: 0.8730\n",
      "Epoch 6/50\n",
      "10917/10917 [==============================] - 1s 72us/sample - loss: 0.5944 - precision: 0.8678 - val_loss: 0.5913 - val_precision: 0.8687\n",
      "Epoch 7/50\n",
      "10917/10917 [==============================] - 1s 69us/sample - loss: 0.5602 - precision: 0.8815 - val_loss: 0.5661 - val_precision: 0.8677\n",
      "Epoch 8/50\n",
      "10917/10917 [==============================] - 1s 70us/sample - loss: 0.5295 - precision: 0.8881 - val_loss: 0.5398 - val_precision: 0.8753\n",
      "Epoch 9/50\n",
      "10917/10917 [==============================] - 1s 70us/sample - loss: 0.5083 - precision: 0.8901 - val_loss: 0.5286 - val_precision: 0.8705\n",
      "Epoch 10/50\n",
      "10917/10917 [==============================] - 1s 70us/sample - loss: 0.4950 - precision: 0.8948 - val_loss: 0.5012 - val_precision: 0.8827\n",
      "Epoch 11/50\n",
      "10917/10917 [==============================] - 1s 69us/sample - loss: 0.4868 - precision: 0.8943 - val_loss: 0.5040 - val_precision: 0.8879\n",
      "Epoch 12/50\n",
      "10917/10917 [==============================] - 1s 68us/sample - loss: 0.4726 - precision: 0.8958 - val_loss: 0.4837 - val_precision: 0.8928\n",
      "Epoch 13/50\n",
      "10917/10917 [==============================] - 1s 71us/sample - loss: 0.4713 - precision: 0.8949 - val_loss: 0.4911 - val_precision: 0.8928\n",
      "Epoch 14/50\n",
      "10917/10917 [==============================] - 1s 71us/sample - loss: 0.4742 - precision: 0.8977 - val_loss: 0.4919 - val_precision: 0.8839\n",
      "Epoch 15/50\n",
      "10917/10917 [==============================] - 1s 70us/sample - loss: 0.4573 - precision: 0.8985 - val_loss: 0.4743 - val_precision: 0.8900\n",
      "Epoch 16/50\n",
      "10917/10917 [==============================] - 1s 69us/sample - loss: 0.4520 - precision: 0.8999 - val_loss: 0.4560 - val_precision: 0.8922\n",
      "Epoch 17/50\n",
      "10917/10917 [==============================] - 1s 69us/sample - loss: 0.4331 - precision: 0.9058 - val_loss: 0.4502 - val_precision: 0.8918\n",
      "Epoch 18/50\n",
      "10917/10917 [==============================] - 1s 69us/sample - loss: 0.4299 - precision: 0.9055 - val_loss: 0.4532 - val_precision: 0.8851\n",
      "Epoch 19/50\n",
      "10917/10917 [==============================] - 1s 69us/sample - loss: 0.4275 - precision: 0.9051 - val_loss: 0.4416 - val_precision: 0.8997\n",
      "Epoch 20/50\n",
      "10917/10917 [==============================] - 1s 69us/sample - loss: 0.4142 - precision: 0.9113 - val_loss: 0.4311 - val_precision: 0.9031\n",
      "Epoch 21/50\n",
      "10917/10917 [==============================] - 1s 68us/sample - loss: 0.4090 - precision: 0.9105 - val_loss: 0.4371 - val_precision: 0.9031\n",
      "Epoch 22/50\n",
      "10917/10917 [==============================] - 1s 68us/sample - loss: 0.4082 - precision: 0.9078 - val_loss: 0.4367 - val_precision: 0.8945\n",
      "Epoch 23/50\n",
      "10917/10917 [==============================] - 1s 68us/sample - loss: 0.4037 - precision: 0.9092 - val_loss: 0.4170 - val_precision: 0.9118\n",
      "Epoch 24/50\n",
      "10917/10917 [==============================] - 1s 68us/sample - loss: 0.3940 - precision: 0.9160 - val_loss: 0.4168 - val_precision: 0.8987\n",
      "Epoch 25/50\n",
      "10917/10917 [==============================] - 1s 69us/sample - loss: 0.3822 - precision: 0.9175 - val_loss: 0.4215 - val_precision: 0.8984\n",
      "Epoch 26/50\n",
      "10917/10917 [==============================] - 1s 69us/sample - loss: 0.3876 - precision: 0.9146 - val_loss: 0.4265 - val_precision: 0.9042\n",
      "Epoch 27/50\n",
      "10917/10917 [==============================] - 1s 69us/sample - loss: 0.3841 - precision: 0.9132 - val_loss: 0.4113 - val_precision: 0.9034\n",
      "Epoch 28/50\n",
      "10917/10917 [==============================] - 1s 69us/sample - loss: 0.3863 - precision: 0.9151 - val_loss: 0.4362 - val_precision: 0.9031\n",
      "Epoch 29/50\n",
      "10917/10917 [==============================] - 1s 69us/sample - loss: 0.3733 - precision: 0.9170 - val_loss: 0.4162 - val_precision: 0.9038\n",
      "Epoch 30/50\n",
      "10917/10917 [==============================] - 1s 69us/sample - loss: 0.3738 - precision: 0.9158 - val_loss: 0.4191 - val_precision: 0.9021\n",
      "Epoch 00030: early stopping\n",
      "10917/10917 [==============================] - 0s 28us/sample - loss: 0.3535 - precision: 0.9269\n",
      "Train loss:  0.35347121044634416\n",
      "Train accuracy:  0.9268921\n",
      "----------------------------------------------------------------------\n",
      "1213/1213 [==============================] - 0s 30us/sample - loss: 0.4191 - precision: 0.9043\n",
      "Test loss:  0.4191223009008076\n",
      "Test accuracy:  0.904323\n",
      "Train on 10917 samples, validate on 1213 samples\n",
      "Epoch 1/50\n",
      "10917/10917 [==============================] - 1s 130us/sample - loss: 1.7996 - precision: 0.3182 - val_loss: 1.4261 - val_precision: 0.8402\n",
      "Epoch 2/50\n",
      "10917/10917 [==============================] - 1s 68us/sample - loss: 1.1366 - precision: 0.7349 - val_loss: 0.9140 - val_precision: 0.8672\n",
      "Epoch 3/50\n",
      "10917/10917 [==============================] - 1s 69us/sample - loss: 0.8249 - precision: 0.8165 - val_loss: 0.6646 - val_precision: 0.8145\n",
      "Epoch 4/50\n",
      "10917/10917 [==============================] - 1s 70us/sample - loss: 0.6945 - precision: 0.8333 - val_loss: 0.5793 - val_precision: 0.8913\n",
      "Epoch 5/50\n",
      "10917/10917 [==============================] - 1s 69us/sample - loss: 0.6161 - precision: 0.8563 - val_loss: 0.5332 - val_precision: 0.9002\n",
      "Epoch 6/50\n",
      "10917/10917 [==============================] - 1s 68us/sample - loss: 0.5684 - precision: 0.8842 - val_loss: 0.5360 - val_precision: 0.9014\n",
      "Epoch 7/50\n",
      "10917/10917 [==============================] - 1s 68us/sample - loss: 0.5346 - precision: 0.8855 - val_loss: 0.4411 - val_precision: 0.9135\n",
      "Epoch 8/50\n",
      "10917/10917 [==============================] - 1s 70us/sample - loss: 0.5260 - precision: 0.8894 - val_loss: 0.4618 - val_precision: 0.8835\n",
      "Epoch 9/50\n",
      "10917/10917 [==============================] - 1s 69us/sample - loss: 0.5169 - precision: 0.8877 - val_loss: 0.4315 - val_precision: 0.9077\n",
      "Epoch 10/50\n",
      "10917/10917 [==============================] - 1s 68us/sample - loss: 0.4986 - precision: 0.8897 - val_loss: 0.4742 - val_precision: 0.9089\n",
      "Epoch 11/50\n",
      "10917/10917 [==============================] - 1s 69us/sample - loss: 0.4974 - precision: 0.8942 - val_loss: 0.4768 - val_precision: 0.8791\n",
      "Epoch 12/50\n",
      "10917/10917 [==============================] - 1s 68us/sample - loss: 0.4914 - precision: 0.8960 - val_loss: 0.4302 - val_precision: 0.9038\n",
      "Epoch 13/50\n",
      "10917/10917 [==============================] - 1s 70us/sample - loss: 0.4736 - precision: 0.9023 - val_loss: 0.4031 - val_precision: 0.9126\n",
      "Epoch 14/50\n",
      "10917/10917 [==============================] - 1s 68us/sample - loss: 0.4652 - precision: 0.8974 - val_loss: 0.3816 - val_precision: 0.9246\n",
      "Epoch 15/50\n",
      "10917/10917 [==============================] - 1s 69us/sample - loss: 0.4420 - precision: 0.9051 - val_loss: 0.3846 - val_precision: 0.9116\n",
      "Epoch 16/50\n",
      "10917/10917 [==============================] - 1s 68us/sample - loss: 0.4378 - precision: 0.9045 - val_loss: 0.3703 - val_precision: 0.9103\n",
      "Epoch 17/50\n",
      "10917/10917 [==============================] - 1s 68us/sample - loss: 0.4330 - precision: 0.9056 - val_loss: 0.3734 - val_precision: 0.9378\n",
      "Epoch 18/50\n",
      "10917/10917 [==============================] - 1s 69us/sample - loss: 0.4187 - precision: 0.9117 - val_loss: 0.3577 - val_precision: 0.9272\n",
      "Epoch 19/50\n",
      "10917/10917 [==============================] - 1s 69us/sample - loss: 0.4283 - precision: 0.9098 - val_loss: 0.3604 - val_precision: 0.9161\n",
      "Epoch 20/50\n",
      "10917/10917 [==============================] - 1s 69us/sample - loss: 0.4179 - precision: 0.9095 - val_loss: 0.3616 - val_precision: 0.9210\n",
      "Epoch 21/50\n",
      "10917/10917 [==============================] - 1s 69us/sample - loss: 0.4139 - precision: 0.9120 - val_loss: 0.3603 - val_precision: 0.9158\n",
      "Epoch 00021: early stopping\n",
      "10917/10917 [==============================] - 0s 28us/sample - loss: 0.3900 - precision: 0.9123\n",
      "Train loss:  0.38999607764321653\n",
      "Train accuracy:  0.91225666\n",
      "----------------------------------------------------------------------\n",
      "1213/1213 [==============================] - 0s 33us/sample - loss: 0.3603 - precision: 0.9155\n",
      "Test loss:  0.3602746457524862\n",
      "Test accuracy:  0.9155115\n",
      "Train on 10917 samples, validate on 1213 samples\n",
      "Epoch 1/50\n",
      "10917/10917 [==============================] - 1s 137us/sample - loss: 1.7940 - precision: 0.3448 - val_loss: 1.6224 - val_precision: 0.7760\n",
      "Epoch 2/50\n",
      "10917/10917 [==============================] - 1s 68us/sample - loss: 1.1135 - precision: 0.7808 - val_loss: 0.8808 - val_precision: 0.8203\n",
      "Epoch 3/50\n",
      "10917/10917 [==============================] - 1s 68us/sample - loss: 0.8054 - precision: 0.8224 - val_loss: 0.7772 - val_precision: 0.8056\n",
      "Epoch 4/50\n",
      "10917/10917 [==============================] - 1s 68us/sample - loss: 0.6630 - precision: 0.8549 - val_loss: 0.6959 - val_precision: 0.8298\n",
      "Epoch 5/50\n",
      "10917/10917 [==============================] - 1s 68us/sample - loss: 0.6123 - precision: 0.8677 - val_loss: 0.6458 - val_precision: 0.8755\n",
      "Epoch 6/50\n",
      "10917/10917 [==============================] - 1s 68us/sample - loss: 0.5638 - precision: 0.8894 - val_loss: 0.6093 - val_precision: 0.8718\n",
      "Epoch 7/50\n",
      "10917/10917 [==============================] - 1s 68us/sample - loss: 0.5190 - precision: 0.8979 - val_loss: 0.5337 - val_precision: 0.8973\n",
      "Epoch 8/50\n",
      "10917/10917 [==============================] - 1s 69us/sample - loss: 0.4998 - precision: 0.8971 - val_loss: 0.5271 - val_precision: 0.8875\n",
      "Epoch 9/50\n",
      "10917/10917 [==============================] - 1s 67us/sample - loss: 0.4817 - precision: 0.9028 - val_loss: 0.5363 - val_precision: 0.8961\n",
      "Epoch 10/50\n",
      "10917/10917 [==============================] - 1s 68us/sample - loss: 0.4679 - precision: 0.9028 - val_loss: 0.5140 - val_precision: 0.8992\n",
      "Epoch 11/50\n",
      "10917/10917 [==============================] - 1s 67us/sample - loss: 0.4502 - precision: 0.9100 - val_loss: 0.5052 - val_precision: 0.8967\n",
      "Epoch 12/50\n",
      "10917/10917 [==============================] - 1s 68us/sample - loss: 0.4445 - precision: 0.9078 - val_loss: 0.5011 - val_precision: 0.8940\n",
      "Epoch 13/50\n",
      "10917/10917 [==============================] - 1s 69us/sample - loss: 0.4324 - precision: 0.9146 - val_loss: 0.4935 - val_precision: 0.8908\n",
      "Epoch 14/50\n",
      "10917/10917 [==============================] - 1s 69us/sample - loss: 0.4347 - precision: 0.9110 - val_loss: 0.4820 - val_precision: 0.8975\n",
      "Epoch 15/50\n",
      "10917/10917 [==============================] - 1s 68us/sample - loss: 0.4268 - precision: 0.9127 - val_loss: 0.4937 - val_precision: 0.8929\n",
      "Epoch 16/50\n",
      "10917/10917 [==============================] - 1s 69us/sample - loss: 0.4209 - precision: 0.9118 - val_loss: 0.4819 - val_precision: 0.8939\n",
      "Epoch 17/50\n",
      "10917/10917 [==============================] - 1s 69us/sample - loss: 0.4096 - precision: 0.9184 - val_loss: 0.4675 - val_precision: 0.8921\n",
      "Epoch 18/50\n",
      "10917/10917 [==============================] - 1s 67us/sample - loss: 0.4053 - precision: 0.9127 - val_loss: 0.4647 - val_precision: 0.9050\n",
      "Epoch 19/50\n",
      "10917/10917 [==============================] - 1s 69us/sample - loss: 0.4072 - precision: 0.9181 - val_loss: 0.4614 - val_precision: 0.9065\n",
      "Epoch 20/50\n",
      "10917/10917 [==============================] - 1s 70us/sample - loss: 0.3956 - precision: 0.9181 - val_loss: 0.4529 - val_precision: 0.8962\n",
      "Epoch 21/50\n",
      "10917/10917 [==============================] - 1s 68us/sample - loss: 0.4013 - precision: 0.9149 - val_loss: 0.4756 - val_precision: 0.8925\n",
      "Epoch 22/50\n",
      "10917/10917 [==============================] - 1s 68us/sample - loss: 0.3885 - precision: 0.9187 - val_loss: 0.4488 - val_precision: 0.9035\n",
      "Epoch 23/50\n",
      "10917/10917 [==============================] - 1s 68us/sample - loss: 0.3782 - precision: 0.9217 - val_loss: 0.4567 - val_precision: 0.8932\n",
      "Epoch 24/50\n",
      "10917/10917 [==============================] - 1s 69us/sample - loss: 0.3818 - precision: 0.9190 - val_loss: 0.4461 - val_precision: 0.8986\n",
      "Epoch 25/50\n",
      "10917/10917 [==============================] - 1s 68us/sample - loss: 0.3894 - precision: 0.9180 - val_loss: 0.4431 - val_precision: 0.9044\n",
      "Epoch 26/50\n",
      "10917/10917 [==============================] - 1s 68us/sample - loss: 0.3657 - precision: 0.9254 - val_loss: 0.4327 - val_precision: 0.9073\n",
      "Epoch 27/50\n",
      "10917/10917 [==============================] - 1s 69us/sample - loss: 0.3678 - precision: 0.9226 - val_loss: 0.4472 - val_precision: 0.8917\n",
      "Epoch 28/50\n",
      "10917/10917 [==============================] - 1s 69us/sample - loss: 0.3614 - precision: 0.9209 - val_loss: 0.4358 - val_precision: 0.8994\n",
      "Epoch 29/50\n",
      "10917/10917 [==============================] - 1s 68us/sample - loss: 0.3545 - precision: 0.9244 - val_loss: 0.4257 - val_precision: 0.9112\n",
      "Epoch 30/50\n",
      "10917/10917 [==============================] - 1s 69us/sample - loss: 0.3472 - precision: 0.9233 - val_loss: 0.4300 - val_precision: 0.9160\n",
      "Epoch 31/50\n",
      "10917/10917 [==============================] - 1s 68us/sample - loss: 0.3457 - precision: 0.9258 - val_loss: 0.4462 - val_precision: 0.8943\n",
      "Epoch 32/50\n",
      "10917/10917 [==============================] - 1s 70us/sample - loss: 0.3427 - precision: 0.9267 - val_loss: 0.4294 - val_precision: 0.8913\n",
      "Epoch 00032: early stopping\n",
      "10917/10917 [==============================] - 0s 28us/sample - loss: 0.3207 - precision: 0.9345\n",
      "Train loss:  0.32072427495119715\n",
      "Train accuracy:  0.9344553\n",
      "----------------------------------------------------------------------\n",
      "1213/1213 [==============================] - 0s 30us/sample - loss: 0.4294 - precision: 0.8919\n",
      "Test loss:  0.4293607538727228\n",
      "Test accuracy:  0.8919302\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 10917 samples, validate on 1213 samples\n",
      "Epoch 1/50\n",
      "10917/10917 [==============================] - 2s 145us/sample - loss: 1.7798 - precision: 0.4330 - val_loss: 1.3440 - val_precision: 0.7200\n",
      "Epoch 2/50\n",
      "10917/10917 [==============================] - 1s 71us/sample - loss: 1.1102 - precision: 0.8241 - val_loss: 0.8414 - val_precision: 0.7928\n",
      "Epoch 3/50\n",
      "10917/10917 [==============================] - 1s 69us/sample - loss: 0.7900 - precision: 0.8160 - val_loss: 0.6891 - val_precision: 0.8293\n",
      "Epoch 4/50\n",
      "10917/10917 [==============================] - 1s 69us/sample - loss: 0.6950 - precision: 0.8349 - val_loss: 0.6190 - val_precision: 0.8859\n",
      "Epoch 5/50\n",
      "10917/10917 [==============================] - 1s 69us/sample - loss: 0.6145 - precision: 0.8638 - val_loss: 0.5434 - val_precision: 0.8849\n",
      "Epoch 6/50\n",
      "10917/10917 [==============================] - 1s 70us/sample - loss: 0.5868 - precision: 0.8708 - val_loss: 0.5208 - val_precision: 0.8901\n",
      "Epoch 7/50\n",
      "10917/10917 [==============================] - 1s 69us/sample - loss: 0.5297 - precision: 0.8922 - val_loss: 0.4731 - val_precision: 0.9105\n",
      "Epoch 8/50\n",
      "10917/10917 [==============================] - 1s 69us/sample - loss: 0.5157 - precision: 0.8911 - val_loss: 0.4451 - val_precision: 0.9020\n",
      "Epoch 9/50\n",
      "10917/10917 [==============================] - 1s 69us/sample - loss: 0.5057 - precision: 0.8954 - val_loss: 0.4535 - val_precision: 0.9034\n",
      "Epoch 10/50\n",
      "10917/10917 [==============================] - 1s 69us/sample - loss: 0.4957 - precision: 0.8965 - val_loss: 0.4553 - val_precision: 0.9133\n",
      "Epoch 11/50\n",
      "10917/10917 [==============================] - 1s 69us/sample - loss: 0.4715 - precision: 0.9062 - val_loss: 0.4169 - val_precision: 0.9110\n",
      "Epoch 12/50\n",
      "10917/10917 [==============================] - 1s 71us/sample - loss: 0.4550 - precision: 0.9062 - val_loss: 0.4237 - val_precision: 0.8996\n",
      "Epoch 13/50\n",
      "10917/10917 [==============================] - 1s 69us/sample - loss: 0.4583 - precision: 0.9020 - val_loss: 0.4111 - val_precision: 0.9040\n",
      "Epoch 14/50\n",
      "10917/10917 [==============================] - 1s 70us/sample - loss: 0.4510 - precision: 0.9122 - val_loss: 0.4159 - val_precision: 0.9188\n",
      "Epoch 15/50\n",
      "10917/10917 [==============================] - 1s 67us/sample - loss: 0.4492 - precision: 0.9086 - val_loss: 0.3896 - val_precision: 0.9147\n",
      "Epoch 16/50\n",
      "10917/10917 [==============================] - 1s 68us/sample - loss: 0.4430 - precision: 0.9105 - val_loss: 0.3778 - val_precision: 0.9263\n",
      "Epoch 17/50\n",
      "10917/10917 [==============================] - 1s 69us/sample - loss: 0.4233 - precision: 0.9124 - val_loss: 0.3758 - val_precision: 0.9243\n",
      "Epoch 18/50\n",
      "10917/10917 [==============================] - 1s 68us/sample - loss: 0.4228 - precision: 0.9153 - val_loss: 0.3732 - val_precision: 0.9239\n",
      "Epoch 19/50\n",
      "10917/10917 [==============================] - 1s 68us/sample - loss: 0.4102 - precision: 0.9144 - val_loss: 0.3744 - val_precision: 0.9283\n",
      "Epoch 20/50\n",
      "10917/10917 [==============================] - 1s 68us/sample - loss: 0.4165 - precision: 0.9123 - val_loss: 0.3706 - val_precision: 0.9218\n",
      "Epoch 21/50\n",
      "10917/10917 [==============================] - 1s 69us/sample - loss: 0.4043 - precision: 0.9145 - val_loss: 0.3505 - val_precision: 0.9254\n",
      "Epoch 22/50\n",
      "10917/10917 [==============================] - 1s 69us/sample - loss: 0.3932 - precision: 0.9162 - val_loss: 0.3664 - val_precision: 0.9287\n",
      "Epoch 23/50\n",
      "10917/10917 [==============================] - 1s 70us/sample - loss: 0.3879 - precision: 0.9205 - val_loss: 0.3499 - val_precision: 0.9200\n",
      "Epoch 24/50\n",
      "10917/10917 [==============================] - 1s 67us/sample - loss: 0.3834 - precision: 0.9176 - val_loss: 0.3584 - val_precision: 0.9251\n",
      "Epoch 25/50\n",
      "10917/10917 [==============================] - 1s 70us/sample - loss: 0.3804 - precision: 0.9166 - val_loss: 0.3763 - val_precision: 0.9112\n",
      "Epoch 26/50\n",
      "10917/10917 [==============================] - 1s 69us/sample - loss: 0.3905 - precision: 0.9112 - val_loss: 0.3598 - val_precision: 0.9108\n",
      "Epoch 00026: early stopping\n",
      "10917/10917 [==============================] - 0s 28us/sample - loss: 0.3670 - precision: 0.9191\n",
      "Train loss:  0.3670106629175702\n",
      "Train accuracy:  0.9190688\n",
      "----------------------------------------------------------------------\n",
      "1213/1213 [==============================] - 0s 30us/sample - loss: 0.3598 - precision: 0.9121\n",
      "Test loss:  0.35978926156831004\n",
      "Test accuracy:  0.9121216\n",
      "Testing Accuracy: 87.222%\n",
      "F-score(macro): 0.72\n",
      "F-score(micro): 0.872\n",
      "Precision: 0.75\n",
      "Recall: 0.714\n",
      "\n",
      "It took 219.59295 seconds to compute.\n"
     ]
    }
   ],
   "source": [
    "#@title Please choose the run type: { form-width: \"250px\" }\n",
    "run_type = \"10_fold_regular\" #@param [\"10_fold_regular\", \"10_fold_grand_mean\"]\n",
    "#@markdown * 10_fold_grand_mean will run 10_fold_regular for 30 times.\n",
    "# ========================= Machine learning models ======================\n",
    "\n",
    "if (algorithm == \"SVM\"):\n",
    "    # ========== 1. Support Vector Machine (SVM) ==========\n",
    "    \n",
    "    # ==========  Hyperparameter tuning    \n",
    "    #svm_params = evaal.SVM_tuning(reduced_X, y)\n",
    "    svm_params = {'C': 50, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
    "    \n",
    "    # ==========  Model evaluation using 10-fold cross-validation\n",
    "#    evaal.svm_eval(reduced_X, y, svm_params, run_type)\n",
    "    evaal.svm_eval(reduced_X, y, svm_params, run_type)\n",
    "\n",
    "elif (algorithm == \"BiLSTM\"):\n",
    "    # ========== 2. Deep learning ==========\n",
    "    \n",
    "    # ========== One-hot encoding    \n",
    "    X_ohe, y_ohe = prp.one_hot_encoding(reduced_X, y)    \n",
    "    \n",
    "    # ========== Bidirectional Long short-term memory networks (Bi-LSTMs)\n",
    "    # ========== Model evaluation using 10-fold Cross-validation\n",
    "#    evaal.lstm_eval(reduced_X, y_ohe, run_type)\n",
    "    evaal.lstm_eval(reduced_X, y_ohe, run_type)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QmYHU5Nih6-a"
   },
   "outputs": [],
   "source": [
    "func.beeep()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "protein_subcellular_localization.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
